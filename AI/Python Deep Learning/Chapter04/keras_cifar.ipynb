{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We'll download the dataset first:"
      ],
      "metadata": {
        "id": "-h2cwJZ4COZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(X_train, Y_train), (X_validation, Y_validation) = \\\n",
        "    tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, 10)\n",
        "Y_validation = tf.keras.utils.to_categorical(Y_validation, 10)"
      ],
      "metadata": {
        "id": "8wrlyOsjCaJI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a35b9c-8599-4700-c3f8-68b80fa94923"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll instantiate a DataGenerator, which will normalize the train and test datasets, and will provide data augmentation during training:"
      ],
      "metadata": {
        "id": "4wUoT2jBCos1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True)\n",
        "\n",
        "# Apply z-normalization on the training set\n",
        "data_generator.fit(X_train)\n",
        "\n",
        "# Standardize the validation set\n",
        "X_validation = data_generator.standardize(X_validation.astype('float32'))"
      ],
      "metadata": {
        "id": "Nc5QRbi5CxBz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll define the CNN model:"
      ],
      "metadata": {
        "id": "MpDra_dnC05b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, BatchNormalization, Activation, Flatten\n",
        "\n",
        "model = Sequential(layers=[\n",
        "    Conv2D(32, (3, 3),\n",
        "           padding='same',\n",
        "           input_shape=X_train.shape[1:]),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(32, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    Conv2D(128, (3, 3)),\n",
        "    BatchNormalization(),\n",
        "    Activation('gelu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "5ZjHhpfIC23L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll define the optimization parameters:"
      ],
      "metadata": {
        "id": "9rb9N7AOC60z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfQH4wiZC9zj",
        "outputId": "24155faf-f0f2-4e92-f488-23da60aaec2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 6, 6, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 293,930\n",
            "Trainable params: 293,034\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we'll run the training and evaluation:"
      ],
      "metadata": {
        "id": "1_7t7qVnDAt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "model.fit(\n",
        "    x=data_generator.flow(x=X_train,\n",
        "                          y=Y_train,\n",
        "                          batch_size=batch_size),\n",
        "    steps_per_epoch=len(X_train) // batch_size,\n",
        "    epochs=100,\n",
        "    verbose=1,\n",
        "    validation_data=(X_validation, Y_validation),\n",
        "    workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LguIGCzcDFPc",
        "outputId": "088e8087-25c0-4719-a8fb-177f255964dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 27s 15ms/step - loss: 1.6768 - accuracy: 0.4029 - val_loss: 1.3441 - val_accuracy: 0.5032\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 1.2025 - accuracy: 0.5667 - val_loss: 1.1317 - val_accuracy: 0.5964\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 1.0374 - accuracy: 0.6295 - val_loss: 0.8895 - val_accuracy: 0.6794\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.9352 - accuracy: 0.6662 - val_loss: 0.9180 - val_accuracy: 0.6747\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.8696 - accuracy: 0.6903 - val_loss: 0.7886 - val_accuracy: 0.7207\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.8214 - accuracy: 0.7087 - val_loss: 0.8486 - val_accuracy: 0.6986\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7867 - accuracy: 0.7223 - val_loss: 0.7121 - val_accuracy: 0.7527\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.7490 - accuracy: 0.7362 - val_loss: 0.7200 - val_accuracy: 0.7452\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.7258 - accuracy: 0.7444 - val_loss: 0.6543 - val_accuracy: 0.7663\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6933 - accuracy: 0.7557 - val_loss: 0.6609 - val_accuracy: 0.7650\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.6744 - accuracy: 0.7634 - val_loss: 0.6105 - val_accuracy: 0.7883\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6520 - accuracy: 0.7696 - val_loss: 0.5758 - val_accuracy: 0.7983\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6420 - accuracy: 0.7759 - val_loss: 0.5978 - val_accuracy: 0.7873\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6212 - accuracy: 0.7824 - val_loss: 0.5587 - val_accuracy: 0.8043\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.6103 - accuracy: 0.7860 - val_loss: 0.5756 - val_accuracy: 0.7973\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5948 - accuracy: 0.7899 - val_loss: 0.5614 - val_accuracy: 0.8022\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5806 - accuracy: 0.7969 - val_loss: 0.5700 - val_accuracy: 0.8011\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5726 - accuracy: 0.7994 - val_loss: 0.5403 - val_accuracy: 0.8113\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5599 - accuracy: 0.8041 - val_loss: 0.5312 - val_accuracy: 0.8107\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.5504 - accuracy: 0.8070 - val_loss: 0.5341 - val_accuracy: 0.8138\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5385 - accuracy: 0.8123 - val_loss: 0.5260 - val_accuracy: 0.8147\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5370 - accuracy: 0.8115 - val_loss: 0.5099 - val_accuracy: 0.8241\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5269 - accuracy: 0.8153 - val_loss: 0.5280 - val_accuracy: 0.8161\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.5219 - accuracy: 0.8176 - val_loss: 0.4969 - val_accuracy: 0.8287\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 0.5156 - accuracy: 0.8193 - val_loss: 0.5138 - val_accuracy: 0.8206\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 16s 16ms/step - loss: 0.5140 - accuracy: 0.8200 - val_loss: 0.5100 - val_accuracy: 0.8230\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 0.4980 - accuracy: 0.8257 - val_loss: 0.4994 - val_accuracy: 0.8306\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4930 - accuracy: 0.8272 - val_loss: 0.4728 - val_accuracy: 0.8377\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4919 - accuracy: 0.8285 - val_loss: 0.5170 - val_accuracy: 0.8226\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4860 - accuracy: 0.8291 - val_loss: 0.5009 - val_accuracy: 0.8259\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4801 - accuracy: 0.8313 - val_loss: 0.4826 - val_accuracy: 0.8332\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4754 - accuracy: 0.8333 - val_loss: 0.4551 - val_accuracy: 0.8429\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 0.4743 - accuracy: 0.8335 - val_loss: 0.4864 - val_accuracy: 0.8292\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4666 - accuracy: 0.8373 - val_loss: 0.4891 - val_accuracy: 0.8284\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4617 - accuracy: 0.8390 - val_loss: 0.4712 - val_accuracy: 0.8392\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 15s 14ms/step - loss: 0.4594 - accuracy: 0.8400 - val_loss: 0.4666 - val_accuracy: 0.8400\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4553 - accuracy: 0.8410 - val_loss: 0.5299 - val_accuracy: 0.8167\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4519 - accuracy: 0.8423 - val_loss: 0.4536 - val_accuracy: 0.8422\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.4471 - accuracy: 0.8444 - val_loss: 0.4851 - val_accuracy: 0.8337\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4458 - accuracy: 0.8437 - val_loss: 0.4523 - val_accuracy: 0.8480\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4412 - accuracy: 0.8449 - val_loss: 0.4729 - val_accuracy: 0.8386\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4397 - accuracy: 0.8470 - val_loss: 0.4687 - val_accuracy: 0.8424\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4336 - accuracy: 0.8489 - val_loss: 0.4426 - val_accuracy: 0.8487\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4324 - accuracy: 0.8466 - val_loss: 0.4478 - val_accuracy: 0.8452\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4327 - accuracy: 0.8487 - val_loss: 0.4332 - val_accuracy: 0.8525\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4303 - accuracy: 0.8496 - val_loss: 0.4521 - val_accuracy: 0.8454\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4236 - accuracy: 0.8513 - val_loss: 0.4606 - val_accuracy: 0.8426\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4281 - accuracy: 0.8512 - val_loss: 0.4337 - val_accuracy: 0.8515\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4191 - accuracy: 0.8510 - val_loss: 0.4525 - val_accuracy: 0.8488\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4168 - accuracy: 0.8531 - val_loss: 0.4362 - val_accuracy: 0.8526\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4173 - accuracy: 0.8544 - val_loss: 0.4311 - val_accuracy: 0.8552\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4081 - accuracy: 0.8566 - val_loss: 0.4441 - val_accuracy: 0.8524\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4135 - accuracy: 0.8548 - val_loss: 0.4444 - val_accuracy: 0.8508\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4109 - accuracy: 0.8551 - val_loss: 0.4426 - val_accuracy: 0.8514\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4055 - accuracy: 0.8584 - val_loss: 0.4344 - val_accuracy: 0.8547\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4040 - accuracy: 0.8580 - val_loss: 0.4220 - val_accuracy: 0.8594\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4038 - accuracy: 0.8580 - val_loss: 0.4293 - val_accuracy: 0.8580\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3960 - accuracy: 0.8594 - val_loss: 0.4348 - val_accuracy: 0.8538\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3991 - accuracy: 0.8597 - val_loss: 0.4395 - val_accuracy: 0.8521\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.4015 - accuracy: 0.8589 - val_loss: 0.4371 - val_accuracy: 0.8518\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3936 - accuracy: 0.8601 - val_loss: 0.4264 - val_accuracy: 0.8571\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3860 - accuracy: 0.8631 - val_loss: 0.4280 - val_accuracy: 0.8578\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3903 - accuracy: 0.8635 - val_loss: 0.4185 - val_accuracy: 0.8585\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3914 - accuracy: 0.8610 - val_loss: 0.4220 - val_accuracy: 0.8579\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3868 - accuracy: 0.8647 - val_loss: 0.4231 - val_accuracy: 0.8591\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3856 - accuracy: 0.8635 - val_loss: 0.4505 - val_accuracy: 0.8515\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3837 - accuracy: 0.8658 - val_loss: 0.4377 - val_accuracy: 0.8551\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3826 - accuracy: 0.8638 - val_loss: 0.4300 - val_accuracy: 0.8602\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3776 - accuracy: 0.8660 - val_loss: 0.4149 - val_accuracy: 0.8628\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3817 - accuracy: 0.8665 - val_loss: 0.4305 - val_accuracy: 0.8574\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3798 - accuracy: 0.8657 - val_loss: 0.4154 - val_accuracy: 0.8626\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3801 - accuracy: 0.8665 - val_loss: 0.4319 - val_accuracy: 0.8553\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3776 - accuracy: 0.8664 - val_loss: 0.4214 - val_accuracy: 0.8637\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3725 - accuracy: 0.8699 - val_loss: 0.4406 - val_accuracy: 0.8538\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3792 - accuracy: 0.8666 - val_loss: 0.4230 - val_accuracy: 0.8586\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3698 - accuracy: 0.8708 - val_loss: 0.4376 - val_accuracy: 0.8558\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3632 - accuracy: 0.8702 - val_loss: 0.4308 - val_accuracy: 0.8564\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3695 - accuracy: 0.8702 - val_loss: 0.4270 - val_accuracy: 0.8587\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3693 - accuracy: 0.8689 - val_loss: 0.4327 - val_accuracy: 0.8581\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3622 - accuracy: 0.8725 - val_loss: 0.4270 - val_accuracy: 0.8594\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3669 - accuracy: 0.8697 - val_loss: 0.4218 - val_accuracy: 0.8603\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3647 - accuracy: 0.8714 - val_loss: 0.4113 - val_accuracy: 0.8677\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3595 - accuracy: 0.8733 - val_loss: 0.4159 - val_accuracy: 0.8640\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3568 - accuracy: 0.8744 - val_loss: 0.4118 - val_accuracy: 0.8661\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3627 - accuracy: 0.8725 - val_loss: 0.4126 - val_accuracy: 0.8609\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3568 - accuracy: 0.8738 - val_loss: 0.4337 - val_accuracy: 0.8558\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3620 - accuracy: 0.8717 - val_loss: 0.4090 - val_accuracy: 0.8654\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3537 - accuracy: 0.8754 - val_loss: 0.4157 - val_accuracy: 0.8597\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3584 - accuracy: 0.8711 - val_loss: 0.4249 - val_accuracy: 0.8608\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3605 - accuracy: 0.8737 - val_loss: 0.4061 - val_accuracy: 0.8656\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3528 - accuracy: 0.8752 - val_loss: 0.4044 - val_accuracy: 0.8670\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3524 - accuracy: 0.8757 - val_loss: 0.4059 - val_accuracy: 0.8651\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3577 - accuracy: 0.8742 - val_loss: 0.4132 - val_accuracy: 0.8661\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3501 - accuracy: 0.8768 - val_loss: 0.4215 - val_accuracy: 0.8606\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 15s 15ms/step - loss: 0.3498 - accuracy: 0.8762 - val_loss: 0.3973 - val_accuracy: 0.8681\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3476 - accuracy: 0.8772 - val_loss: 0.4033 - val_accuracy: 0.8665\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3450 - accuracy: 0.8778 - val_loss: 0.4166 - val_accuracy: 0.8630\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3497 - accuracy: 0.8759 - val_loss: 0.3986 - val_accuracy: 0.8687\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3444 - accuracy: 0.8797 - val_loss: 0.4019 - val_accuracy: 0.8666\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 14s 14ms/step - loss: 0.3470 - accuracy: 0.8773 - val_loss: 0.4097 - val_accuracy: 0.8681\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a27830130>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}